algorithm:
  module: algorithms
  name: MonteCarloDropout
  params:
    p: 0.05
    num_samples: 10000

model:
  module: models
  name: MLP

optimizer:
  module: torch.optim
  name: Adam

dataset:
  module: dataloader
  name: BostonDataset
  params: None
  #  num_samples: 500
  #  domain: !!python/tuple [0, 10]
  # more if needed

sampler:
  module: dataloader
  name:
  params:
    neighbors: 100
    ssu: 100
    psu: 100

parameters:
  batch_size: 500
  num_epochs: 10000
  save_summary_steps: 1
  learning_rate: 0.001 # ?
